{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1728879,"sourceType":"datasetVersion","datasetId":1025978}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"df.iloc[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:23:57.784363Z","iopub.execute_input":"2025-05-01T10:23:57.784685Z","iopub.status.idle":"2025-05-01T10:23:57.793685Z","shell.execute_reply.started":"2025-05-01T10:23:57.784662Z","shell.execute_reply":"2025-05-01T10:23:57.792932Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2900375399.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  df.iloc[0][0]\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[37523, 11851,    25,  1400,    12,    33,   539, 11959, 45305,   198,\n           198, 41222,    25,   198, 14692,    16,   269,    13, 14245, 11856,\n          7586,  7543,  1600,   366,    16,    14,    17,   269,    13, 28959,\n           515,  7545,  1600,   366,    16,    14,    17, 23053,    13, 16858,\n          1600,   366,    16,    14,    17,   269,    13,  5445, 14380,   357,\n         43106,   504, 42501,   366,    17,   309, 24145,    13,  9215,   393,\n          6145, 34569,  1600,   366,    18,   352,    14,    17,   269,    13,\n         13197,  2546, 37624, 11464, 50128,  8973,   198,   198, 43993,   507,\n            25,   198, 14692,   818,   257,  4334,   362,    12, 36008, 10746,\n          6839,    11,  5022,  7586,  7543,    11, 14380,    11, 28959,   515,\n          7545,   290,  9215,   393,  6145, 34569, 33283,   366,  1273,   343,\n           625,  7090,  4894,  1566, 11710, 25037,   477,   625,  1353, 33283,\n           366,    33,  9437,   290, 11240,   642,  2431,   517,    13,  7214,\n           572,  4894, 33283,   366,  1273,   343,   287, 16858,   290, 33158,\n            26,  5022,   880, 33283,   366, 12814,   362, 47234,    11,  4268,\n           290,  5485,   656,  1542, 23163,   319, 20302,  3348, 33283,   366,\n          5756,  1302,  1566,  4081,    11,   546,  1542,  2431,   526,    60,\n           198,   198, 24602,  7232,   871,    25, 14631, 33282,  7543,  1600,\n           366, 25433,    74,  1600,   366, 10438,  5049,  1600,   366, 31381,\n          1600,   366,  4360,   353,  1600,   366, 37018,  2546, 37624, 11464,\n         50128,  8973, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n         50256, 50256, 50256, 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(df, test_size = 0.1, random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:17.054701Z","iopub.execute_input":"2025-05-01T10:24:17.055358Z","iopub.status.idle":"2025-05-01T10:24:17.061214Z","shell.execute_reply.started":"2025-05-01T10:24:17.055335Z","shell.execute_reply":"2025-05-01T10:24:17.060177Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:19.138142Z","iopub.execute_input":"2025-05-01T10:24:19.138878Z","iopub.status.idle":"2025-05-01T10:24:19.142118Z","shell.execute_reply.started":"2025-05-01T10:24:19.138852Z","shell.execute_reply":"2025-05-01T10:24:19.141500Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n                model_name,\n                pad_token_id=tokenizer.eos_token_id\n            )\n            \n# Resize token embeddings if needed\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:19.423414Z","iopub.execute_input":"2025-05-01T10:24:19.424118Z","iopub.status.idle":"2025-05-01T10:24:19.710854Z","shell.execute_reply.started":"2025-05-01T10:24:19.424091Z","shell.execute_reply":"2025-05-01T10:24:19.710237Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 1024)"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:23.168226Z","iopub.execute_input":"2025-05-01T10:24:23.168994Z","iopub.status.idle":"2025-05-01T10:24:23.174970Z","shell.execute_reply.started":"2025-05-01T10:24:23.168967Z","shell.execute_reply":"2025-05-01T10:24:23.174244Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 1024)\n    (wpe): Embedding(1024, 1024)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-23): 24 x GPT2Block(\n        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=3072, nx=1024)\n          (c_proj): Conv1D(nf=1024, nx=1024)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=4096, nx=1024)\n          (c_proj): Conv1D(nf=1024, nx=4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"!pip install torchinfo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:26.456998Z","iopub.execute_input":"2025-05-01T10:24:26.457272Z","iopub.status.idle":"2025-05-01T10:24:29.374275Z","shell.execute_reply.started":"2025-05-01T10:24:26.457252Z","shell.execute_reply":"2025-05-01T10:24:29.373443Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from torchinfo import summary\n\nsummary(model)  # Adjust input_size based on your needs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:29.375667Z","iopub.execute_input":"2025-05-01T10:24:29.375960Z","iopub.status.idle":"2025-05-01T10:24:29.400587Z","shell.execute_reply.started":"2025-05-01T10:24:29.375928Z","shell.execute_reply":"2025-05-01T10:24:29.399819Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"===========================================================================\nLayer (type:depth-idx)                             Param #\n===========================================================================\nGPT2LMHeadModel                                    --\n├─GPT2Model: 1-1                                   --\n│    └─Embedding: 2-1                              51,463,168\n│    └─Embedding: 2-2                              1,048,576\n│    └─Dropout: 2-3                                --\n│    └─ModuleList: 2-4                             --\n│    │    └─GPT2Block: 3-1                         12,596,224\n│    │    └─GPT2Block: 3-2                         12,596,224\n│    │    └─GPT2Block: 3-3                         12,596,224\n│    │    └─GPT2Block: 3-4                         12,596,224\n│    │    └─GPT2Block: 3-5                         12,596,224\n│    │    └─GPT2Block: 3-6                         12,596,224\n│    │    └─GPT2Block: 3-7                         12,596,224\n│    │    └─GPT2Block: 3-8                         12,596,224\n│    │    └─GPT2Block: 3-9                         12,596,224\n│    │    └─GPT2Block: 3-10                        12,596,224\n│    │    └─GPT2Block: 3-11                        12,596,224\n│    │    └─GPT2Block: 3-12                        12,596,224\n│    │    └─GPT2Block: 3-13                        12,596,224\n│    │    └─GPT2Block: 3-14                        12,596,224\n│    │    └─GPT2Block: 3-15                        12,596,224\n│    │    └─GPT2Block: 3-16                        12,596,224\n│    │    └─GPT2Block: 3-17                        12,596,224\n│    │    └─GPT2Block: 3-18                        12,596,224\n│    │    └─GPT2Block: 3-19                        12,596,224\n│    │    └─GPT2Block: 3-20                        12,596,224\n│    │    └─GPT2Block: 3-21                        12,596,224\n│    │    └─GPT2Block: 3-22                        12,596,224\n│    │    └─GPT2Block: 3-23                        12,596,224\n│    │    └─GPT2Block: 3-24                        12,596,224\n│    └─LayerNorm: 2-5                              2,048\n├─Linear: 1-2                                      51,463,168\n===========================================================================\nTotal params: 406,286,336\nTrainable params: 406,286,336\nNon-trainable params: 0\n==========================================================================="},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"prompt = \"Generate a chocolate chip cookie recipe with these ingredients: flour, sugar, eggs, chocolate chips\\n\\nRecipe Title:\"\nprompt = tokenizer(prompt,  return_tensors=\"pt\")\n\nparams = {\n                'max_length': 400,\n                'num_return_sequences': 1,\n                'temperature': 0.7,\n                'top_k': 50,\n                'top_p': 0.9,\n                'do_sample': True,\n                'no_repeat_ngram_size': 2,\n                'early_stopping': True\n            }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:33.899978Z","iopub.execute_input":"2025-05-01T10:24:33.900736Z","iopub.status.idle":"2025-05-01T10:24:33.905750Z","shell.execute_reply.started":"2025-05-01T10:24:33.900711Z","shell.execute_reply":"2025-05-01T10:24:33.904920Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"outputs = model.generate(\n            **prompt,\n            **params\n        )\n\nprint(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:24:34.340433Z","iopub.execute_input":"2025-05-01T10:24:34.340955Z","iopub.status.idle":"2025-05-01T10:25:09.673714Z","shell.execute_reply.started":"2025-05-01T10:24:34.340936Z","shell.execute_reply":"2025-05-01T10:25:09.673011Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"tensor([[ 8645,   378,   257, 11311, 11594, 19751,  8364,   351,   777,  9391,\n            25, 10601,    11,  7543,    11,  9653,    11, 11311, 12014,   198,\n           198, 37523, 11851,    25, 24777, 17869, 39606, 26694,   198,    11,\n          6434,    25, 14235,    11, 26088,    11,   290, 14235,   198,    12,\n           352,  6508,   357,    17, 16461,     8,  5576, 29590,  9215,    11,\n         41534,   198,   628,   198,    16,  6508,  7543,   198,    13,   764,\n           764,   198,   286,  7586,  7543,   764,   628,   262,   976,  2033,\n           286, 24178,  9215,   628,    13,   198,   357,    40,   973,   352,\n            14,    19,  6508,  7586,  9215,   329,   428,  8364,     8,   628,\n          1849,    12,   362, 14180,   477,  4007, 10601,   628,   628,   764,\n           357,  5832,   460,   779,   597,  1611,   286, 10601,   345,   588,\n            13,   314,   973,  7586,    11,  2330,    11,   393,   772,  2187,\n         17135, 10601,  2014,   628,   532,   352,   352, 46256,   226,    17,\n         23053, 16871, 11913,   198,   764, 20262,   764,   345,   460,   635,\n           779, 41642,  7543,   393,   477,    12, 29983, 10601,     8,   198,\n          1212,  8364,   460,   307, 15229,   290,   345,  1183,   651,   257,\n          1256,   517, 14746,     0,   628,    12,   513,    14,    23,  6508,\n         19468,  4817,  7543,   628,   438,   352, 23053, 16858,  7925,   198,\n           464,  8364,  3848,   329,  9215,    13,   887,   611,   345,   423,\n           257,  4274, 36741,   345,   714,   635,   655,   779,   262,  9215,\n           287,   262, 14361,    13,  2102,    11,   314,   750,   779,  9215,\n           290,   340,   373,  1049,     0,   198,    40,   635,   973,   262,\n         16858,   290,   262, 11311,    13,  1002,   345,   836,   470,   423,\n         16858,    11,   345,   481,   761,   284,   779,   257,  1310,   517,\n           286,   340,    13,   383, 11311,   318,   845,  7888,    13,   628,\n            40,  1101,   407,  1654,   611,   262,  8364,   318,  3338,   329,\n         11903,    11,   475,   314,  1053,  1775,   617, 34015,   508,   423,\n           550,  2761,   351,   340,   290,   314,  1101,  1654,   326,   338,\n           644,   340,   338,   925,   422,     0,   314,   635,  7668,   287,\n           617, 10912,  1976,   395,   290,   257,  1402,  2033,   357, 10755,\n           352, 22326,     8,   286, 41642, 41642, 49084,   357,  6738,   262,\n         18550, 28960,   737,   632,   338,   845,  6546,   523,   345,  1244,\n           761,   617,  3131,  7543,   611,   534,  5156,   318,   407,  6600,\n           340,     0,   632,   318,  1266,   284,  1309,   262, 11710,  1650,\n           329,   257,  1178,  2431,   878,   345,   751,   340,   284,   262,\n         15756,    13,   632,   815,   307,   845,  2705,   290,  1067,  2178,\n           306,    11,   407,   845, 23408,    13,  4874,   345,  5022,   287,\n           340,    11,   340,   481,   307,  2705,   475,   407, 23408,   290,\n           481,   670,   655,  3734,    13,   357,  1532,   345,   821,  1262,\n           257, 33938,    11,   262,  5022,   318,  1016,   284,   307,   257]])\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"generated_text = tokenizer.decode(\n    outputs[0], \n    skip_special_tokens=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.674923Z","iopub.execute_input":"2025-05-01T10:25:09.675130Z","iopub.status.idle":"2025-05-01T10:25:09.679119Z","shell.execute_reply.started":"2025-05-01T10:25:09.675115Z","shell.execute_reply":"2025-05-01T10:25:09.678450Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"print(generated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.679912Z","iopub.execute_input":"2025-05-01T10:25:09.680263Z","iopub.status.idle":"2025-05-01T10:25:09.698162Z","shell.execute_reply.started":"2025-05-01T10:25:09.680236Z","shell.execute_reply":"2025-05-01T10:25:09.697583Z"}},"outputs":[{"name":"stdout","text":"Generate a chocolate chip cookie recipe with these ingredients: flour, sugar, eggs, chocolate chips\n\nRecipe Title: Chocolate Chip Cookie Recipe\n, Author: Amy, Christine, and Amy\n- 1 cup (2 sticks) unsalted butter, softened\n\n\n\n1 cup sugar\n. . .\n of brown sugar .\n\n the same amount of melted butter\n\n.\n (I used 1/4 cup brown butter for this recipe)\n\n - 2 cups all purpose flour\n\n\n\n . (you can use any kind of flour you like. I used brown, white, or even whole wheat flour.)\n\n - 1 1⁄2 tsp baking powder\n . (. . you can also use powdered sugar or all-purpose flour)\nThis recipe can be doubled and you'll get a lot more cookies!\n\n- 3/8 cup granulated sugar\n\n-- 1 tsp vanilla extract\nThe recipe calls for butter. But if you have a double boiler you could also just use the butter in the oven. However, I did use butter and it was great!\nI also used the vanilla and the chocolate. If you don't have vanilla, you will need to use a little more of it. The chocolate is very thin.\n\nI'm not sure if the recipe is safe for babies, but I've seen some moms who have had problems with it and I'm sure that's what it's made from! I also mixed in some orange zest and a small amount (about 1 teaspoon) of powdered powdered gelatin (from the candy aisle). It's very thick so you might need some extra sugar if your baby is not eating it! It is best to let the mixture sit for a few minutes before you add it to the dough. It should be very soft and crumbly, not very sticky. Once you mix in it, it will be soft but not sticky and will work just fine. (If you're using a mixer, the mix is going to be a\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.699930Z","iopub.execute_input":"2025-05-01T10:25:09.700160Z","iopub.status.idle":"2025-05-01T10:25:09.714513Z","shell.execute_reply.started":"2025-05-01T10:25:09.700146Z","shell.execute_reply":"2025-05-01T10:25:09.713960Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=4,\n    lora_alpha=16,\n    target_modules=[\"c_attn\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.715216Z","iopub.execute_input":"2025-05-01T10:25:09.715427Z","iopub.status.idle":"2025-05-01T10:25:09.760792Z","shell.execute_reply.started":"2025-05-01T10:25:09.715404Z","shell.execute_reply":"2025-05-01T10:25:09.760061Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:51:20.916702Z","iopub.execute_input":"2025-05-01T10:51:20.917406Z","iopub.status.idle":"2025-05-01T10:51:20.924144Z","shell.execute_reply.started":"2025-05-01T10:51:20.917384Z","shell.execute_reply":"2025-05-01T10:51:20.923571Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): GPT2LMHeadModel(\n      (transformer): GPT2Model(\n        (wte): Embedding(50257, 1024)\n        (wpe): Embedding(1024, 1024)\n        (drop): Dropout(p=0.1, inplace=False)\n        (h): ModuleList(\n          (0-23): 24 x GPT2Block(\n            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (attn): GPT2Attention(\n              (c_attn): lora.Linear(\n                (base_layer): Conv1D(nf=3072, nx=1024)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1024, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (c_proj): Conv1D(nf=1024, nx=1024)\n              (attn_dropout): Dropout(p=0.1, inplace=False)\n              (resid_dropout): Dropout(p=0.1, inplace=False)\n            )\n            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (mlp): GPT2MLP(\n              (c_fc): Conv1D(nf=4096, nx=1024)\n              (c_proj): Conv1D(nf=1024, nx=4096)\n              (act): NewGELUActivation()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"summary(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.761348Z","iopub.execute_input":"2025-05-01T10:25:09.761558Z","iopub.status.idle":"2025-05-01T10:25:09.839792Z","shell.execute_reply.started":"2025-05-01T10:25:09.761516Z","shell.execute_reply":"2025-05-01T10:25:09.839225Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                                            Param #\n==========================================================================================\nPeftModelForCausalLM                                              --\n├─LoraModel: 1-1                                                  --\n│    └─GPT2LMHeadModel: 2-1                                       --\n│    │    └─GPT2Model: 3-1                                        355,216,384\n│    │    └─Linear: 3-2                                           (51,463,168)\n==========================================================================================\nTotal params: 406,679,552\nTrainable params: 393,216\nNon-trainable params: 406,286,336\n=========================================================================================="},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"trainable_params = 393216\ntotal_params = 406679552\npercentage_trainable_params = trainable_params * 100 / total_params\nprint(\"Percentage of parameters which are trainable:\",percentage_trainable_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.840356Z","iopub.execute_input":"2025-05-01T10:25:09.840575Z","iopub.status.idle":"2025-05-01T10:25:09.844798Z","shell.execute_reply.started":"2025-05-01T10:25:09.840553Z","shell.execute_reply":"2025-05-01T10:25:09.843948Z"}},"outputs":[{"name":"stdout","text":"Percentage of parameters which are trainable: 0.09668939538912445\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:25:09.845764Z","iopub.execute_input":"2025-05-01T10:25:09.846038Z","iopub.status.idle":"2025-05-01T10:25:09.859947Z","shell.execute_reply.started":"2025-05-01T10:25:09.846023Z","shell.execute_reply":"2025-05-01T10:25:09.859432Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./gpt2-lora\",\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n    logging_steps=1,\n    save_strategy=\"epoch\",\n    fp16=True,  # Set to False if not using GPU with float16 support\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T10:55:21.230393Z","iopub.execute_input":"2025-05-01T10:55:21.230972Z","iopub.status.idle":"2025-05-01T10:55:21.263763Z","shell.execute_reply.started":"2025-05-01T10:55:21.230949Z","shell.execute_reply":"2025-05-01T10:55:21.263199Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, TrainerCallback, pipeline\n\nclass Callbacks(TrainerCallback):\n    def on_save(self, args, state, control, **kwargs):\n        if LoRA:\n            model.save_pretrained(f'./checkpoint-{state.global_step}/lora/')\n        tokenizer.save_pretrained(f'./checkpoint-{state.global_step}/tokenizer/')\n        model.config.to_json_file(f'./checkpoint-{state.global_step}/config.json')\n    def on_log(self, args, state, control, **kwargs):\n        prompt = '你好。<end of turn>'\n        chatbot = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n        model_input = tokenizer.encode(prompt, return_tensors='pt').to('cuda')\n        generated_ids = model.generate(input_ids=model_input, max_length=10, pad_token_id=tokenizer.eos_token_id)\n        generated_text = tokenizer.decode(generated_ids[:, model_input.shape[-1]:][0], skip_special_tokens=True)\n        print(f\"Response to '{prompt}':\", generated_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T11:52:19.584658Z","iopub.execute_input":"2025-04-30T11:52:19.584905Z","iopub.status.idle":"2025-04-30T11:52:19.590777Z","shell.execute_reply.started":"2025-04-30T11:52:19.584888Z","shell.execute_reply":"2025-04-30T11:52:19.590175Z"}},"outputs":[],"execution_count":188},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, TrainerCallback, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.484280Z","iopub.status.idle":"2025-04-30T12:57:49.484497Z","shell.execute_reply.started":"2025-04-30T12:57:49.484395Z","shell.execute_reply":"2025-04-30T12:57:49.484405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Current Device: ', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.485445Z","iopub.status.idle":"2025-04-30T12:57:49.485672Z","shell.execute_reply.started":"2025-04-30T12:57:49.485564Z","shell.execute_reply":"2025-04-30T12:57:49.485573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('gpt2')\nmodel = model.to(device)\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.487679Z","iopub.status.idle":"2025-04-30T12:57:49.488001Z","shell.execute_reply.started":"2025-04-30T12:57:49.487847Z","shell.execute_reply":"2025-04-30T12:57:49.487862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))\nmodel = torch.compile(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.488760Z","iopub.status.idle":"2025-04-30T12:57:49.488986Z","shell.execute_reply.started":"2025-04-30T12:57:49.488864Z","shell.execute_reply":"2025-04-30T12:57:49.488877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = LoraConfig(\n    r=32,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    # tune the embedding layer and prediction head\n    modules_to_save=[\"wte\", \"lm_head\"]\n)\nmodel = get_peft_model(model, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.489838Z","iopub.status.idle":"2025-04-30T12:57:49.490133Z","shell.execute_reply.started":"2025-04-30T12:57:49.489965Z","shell.execute_reply":"2025-04-30T12:57:49.489981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/home/baily/eureka/gpt-2-lora\",\n    overwrite_output_dir=True,\n    num_train_epochs=5,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=128,\n    logging_steps=200,\n    save_steps=2000,\n    save_total_limit=10,\n    warmup_steps=5000,\n    gradient_accumulation_steps=2,\n    learning_rate=3e-5,\n    fp16=True,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.491688Z","iopub.status.idle":"2025-04-30T12:57:49.491959Z","shell.execute_reply.started":"2025-04-30T12:57:49.491839Z","shell.execute_reply":"2025-04-30T12:57:49.491851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_df,\n    eval_dataset=test_df,\n    callbacks=[Callbacks(),]\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T12:57:49.492615Z","iopub.status.idle":"2025-04-30T12:57:49.492873Z","shell.execute_reply.started":"2025-04-30T12:57:49.492760Z","shell.execute_reply":"2025-04-30T12:57:49.492772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/trl.git\n!pip install bitsandbytes>=0.44.0\n!pip install trl==0.12.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:23:10.741722Z","iopub.execute_input":"2025-05-03T11:23:10.742417Z","iopub.status.idle":"2025-05-03T11:23:37.988670Z","shell.execute_reply.started":"2025-05-03T11:23:10.742392Z","shell.execute_reply":"2025-05-03T11:23:37.987519Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/trl.git\n  Cloning https://github.com/huggingface/trl.git to /tmp/pip-req-build-a70rmg0o\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-a70rmg0o\n  Resolved https://github.com/huggingface/trl.git to commit cc044e35b285be7dc062764b3364e1e684db4c7c\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.18.0.dev0) (1.3.0)\nRequirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.18.0.dev0) (3.5.0)\nRequirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.18.0.dev0) (4.51.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (2.5.1+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.18.0.dev0) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl==0.18.0.dev0) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl==0.18.0.dev0) (3.11.16)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.18.0.dev0) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.18.0.dev0) (0.21.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl==0.18.0.dev0) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.18.0.dev0) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.18.0.dev0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.18.0.dev0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.18.0.dev0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.18.0.dev0) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.18.0.dev0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.18.0.dev0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl==0.18.0.dev0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.18.0.dev0) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.18.0.dev0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.18.0.dev0) (2024.2.0)\nBuilding wheels for collected packages: trl\n  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for trl: filename=trl-0.18.0.dev0-py3-none-any.whl size=350386 sha256=76bd4290bffe9ebeb2d5d27e6c34bdd0665b5885e2cf8724d859c85b8bb6994f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-uitck95r/wheels/e7/e5/ec/8cce76372e10e954b47f3893a36ff7c0786d9dbc846efa8860\nSuccessfully built trl\nInstalling collected packages: trl\n  Attempting uninstall: trl\n    Found existing installation: trl 0.12.0\n    Uninstalling trl-0.12.0:\n      Successfully uninstalled trl-0.12.0\nSuccessfully installed trl-0.18.0.dev0\nCollecting trl==0.12.2\n  Downloading trl-0.12.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.12.2) (1.3.0)\nRequirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.12.2) (3.5.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.12.2) (14.0.0)\nCollecting transformers<4.47.0 (from trl==0.12.2)\n  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (2.5.1+cu124)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.2) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl==0.12.2) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.2) (3.11.16)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.47.0->trl==0.12.2) (2024.11.6)\nCollecting tokenizers<0.21,>=0.20 (from transformers<4.47.0->trl==0.12.2)\n  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.12.2) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.12.2) (2.19.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.2) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.12.2) (4.13.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.2) (0.1.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.2) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.2) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.12.2) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.12.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl==0.12.2) (2024.2.0)\nDownloading trl-0.12.2-py3-none-any.whl (365 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers, trl\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\n  Attempting uninstall: trl\n    Found existing installation: trl 0.18.0.dev0\n    Uninstalling trl-0.18.0.dev0:\n      Successfully uninstalled trl-0.18.0.dev0\nSuccessfully installed tokenizers-0.20.3 transformers-4.46.3 trl-0.12.2\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from trl import SFTTrainer\nimport torch\nimport pandas as pd\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:26:57.070272Z","iopub.execute_input":"2025-05-03T11:26:57.070799Z","iopub.status.idle":"2025-05-03T11:26:57.074862Z","shell.execute_reply.started":"2025-05-03T11:26:57.070774Z","shell.execute_reply":"2025-05-03T11:26:57.074151Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"num_samples = 1000\n\ndf = pd.read_csv(\"/kaggle/input/recipenlg/RecipeNLG_dataset.csv\", nrows = num_samples)\ndf = df.drop(columns=['Unnamed: 0', 'link', 'source'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:11:40.856596Z","iopub.execute_input":"2025-05-03T11:11:40.856882Z","iopub.status.idle":"2025-05-03T11:11:40.890792Z","shell.execute_reply.started":"2025-05-03T11:11:40.856860Z","shell.execute_reply":"2025-05-03T11:11:40.889905Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"formatted_texts = []\n\nfor index, row in df.iterrows():\n    title = row['title']\n    ingredients = row['ingredients']\n    directions = row['directions']\n    ner = row['NER']\n\n    text = (\n        f\"Recipe Title: {title}\\n\\n\"\n        f\"Ingredients:\\n{ingredients}\\n\\n\"\n        f\"Instructions:\\n{directions}\\n\\n\"\n        f\"Food Entities: {ner}\"\n    )\n\n    formatted_texts.append(text)\n\ndf['text'] = formatted_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:11:42.234510Z","iopub.execute_input":"2025-05-03T11:11:42.235223Z","iopub.status.idle":"2025-05-03T11:11:42.287825Z","shell.execute_reply.started":"2025-05-03T11:11:42.235198Z","shell.execute_reply":"2025-05-03T11:11:42.287169Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:11:48.589205Z","iopub.execute_input":"2025-05-03T11:11:48.589509Z","iopub.status.idle":"2025-05-03T11:11:48.612678Z","shell.execute_reply.started":"2025-05-03T11:11:48.589490Z","shell.execute_reply":"2025-05-03T11:11:48.611837Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                   title                                        ingredients  \\\n0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n\n                                          directions  \\\n0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n1  [\"Place chipped beef on bottom of baking dish....   \n2  [\"In a slow cooker, combine all ingredients. C...   \n3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n4  [\"Combine first four ingredients and press in ...   \n\n                                                 NER  \\\n0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...   \n1  [\"beef\", \"chicken breasts\", \"cream of mushroom...   \n2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...   \n3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...   \n4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...   \n\n                                                text  \n0  Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...  \n1  Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...  \n2  Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...  \n3  Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...  \n4  Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>NER</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No-Bake Nut Cookies</td>\n      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n      <td>Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jewell Ball'S Chicken</td>\n      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n      <td>[\"Place chipped beef on bottom of baking dish....</td>\n      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n      <td>Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creamy Corn</td>\n      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n      <td>Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chicken Funny</td>\n      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n      <td>Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Reeses Cups(Candy)</td>\n      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n      <td>[\"Combine first four ingredients and press in ...</td>\n      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n      <td>Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model_name = \"gpt2-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:12:50.383631Z","iopub.execute_input":"2025-05-03T11:12:50.383962Z","iopub.status.idle":"2025-05-03T11:12:51.672874Z","shell.execute_reply.started":"2025-05-03T11:12:50.383938Z","shell.execute_reply":"2025-05-03T11:12:51.672148Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab083a2aa383452e8870d76634ba5aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22c1cf752bd40a3a30becca143efdd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c96a68044c704c6bab5f12c098ffe81e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3cbfc140014fb4b99b22e2b274dae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4290f068d45476d93cf935fed01ac99"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name, device_map={\"\": 0}, torch_dtype=torch.float16)\n\nmodel = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:25:45.598299Z","iopub.execute_input":"2025-05-03T11:25:45.598577Z","iopub.status.idle":"2025-05-03T11:25:46.666636Z","shell.execute_reply.started":"2025-05-03T11:25:45.598557Z","shell.execute_reply":"2025-05-03T11:25:46.665701Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"peft_config = LoraConfig(r=4, lora_alpha=16, lora_dropout=0.1, bias='none', task_type='CAUSAL_LM')\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:18:59.543384Z","iopub.execute_input":"2025-05-03T11:18:59.543999Z","iopub.status.idle":"2025-05-03T11:18:59.576070Z","shell.execute_reply.started":"2025-05-03T11:18:59.543977Z","shell.execute_reply":"2025-05-03T11:18:59.575525Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"training_args = TrainingArguments(\n        output_dir=\"/home/baily/eureka/gpt-2-lora\",\n        per_device_train_batch_size=4,\n        optim=\"adamw_torch\",\n        logging_steps=100,\n        learning_rate=2e-4,\n        fp16=True,\n        warmup_ratio=0.1,\n        lr_scheduler_type=\"linear\",\n        num_train_epochs=1,\n        save_strategy=\"epoch\",\n        push_to_hub=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T11:27:47.845024Z","iopub.execute_input":"2025-05-03T11:27:47.845439Z","iopub.status.idle":"2025-05-03T11:27:47.886237Z","shell.execute_reply.started":"2025-05-03T11:27:47.845410Z","shell.execute_reply":"2025-05-03T11:27:47.885308Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install peft==0.4.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T11:40:26.590024Z","iopub.execute_input":"2025-05-05T11:40:26.590591Z","iopub.status.idle":"2025-05-05T11:40:29.619141Z","shell.execute_reply.started":"2025-05-05T11:40:26.590563Z","shell.execute_reply":"2025-05-05T11:40:29.618407Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.11/dist-packages (0.4.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (2.5.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (4.51.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (1.3.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (0.5.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft==0.4.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.4.0) (1.3.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->peft==0.4.0) (0.30.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (4.67.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.4.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft==0.4.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft==0.4.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft==0.4.0) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft==0.4.0) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"mkdir cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T11:40:32.070158Z","iopub.execute_input":"2025-05-05T11:40:32.070774Z","iopub.status.idle":"2025-05-05T11:40:32.187749Z","shell.execute_reply.started":"2025-05-05T11:40:32.070744Z","shell.execute_reply":"2025-05-05T11:40:32.187016Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n#model_name = \"bigscience/bloomz-560m\"\nmodel_name = \"gpt2-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\nfoundation_model = AutoModelForCausalLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:16:17.194043Z","iopub.execute_input":"2025-05-05T12:16:17.194645Z","iopub.status.idle":"2025-05-05T12:16:18.237964Z","shell.execute_reply.started":"2025-05-05T12:16:17.194624Z","shell.execute_reply":"2025-05-05T12:16:18.237420Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\n\nnum_samples = 100000\n\ndf = pd.read_csv(\"/kaggle/input/recipenlg/RecipeNLG_dataset.csv\", nrows = num_samples)\ndf = df.drop(columns=['Unnamed: 0', 'link', 'source'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:16:18.239094Z","iopub.execute_input":"2025-05-05T12:16:18.239345Z","iopub.status.idle":"2025-05-05T12:16:19.420266Z","shell.execute_reply.started":"2025-05-05T12:16:18.239324Z","shell.execute_reply":"2025-05-05T12:16:19.419708Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"formatted_texts = []\n\nfor index, row in df.iterrows():\n    title = row['title']\n    ingredients = row['ingredients']\n    directions = row['directions']\n    ner = row['NER']\n\n    text = (\n        f\"Recipe Title: {title}\\n\\n\"\n        f\"Ingredients:\\n{ingredients}\\n\\n\"\n        f\"Instructions:\\n{directions}\\n\\n\"\n        f\"Food Entities: {ner}\"\n    )\n\n    formatted_texts.append(text)\n\ndf['text'] = formatted_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:16:19.421218Z","iopub.execute_input":"2025-05-05T12:16:19.421470Z","iopub.status.idle":"2025-05-05T12:16:23.484530Z","shell.execute_reply.started":"2025-05-05T12:16:19.421452Z","shell.execute_reply":"2025-05-05T12:16:23.483942Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:16:23.485757Z","iopub.execute_input":"2025-05-05T12:16:23.486095Z","iopub.status.idle":"2025-05-05T12:16:23.493964Z","shell.execute_reply.started":"2025-05-05T12:16:23.486072Z","shell.execute_reply":"2025-05-05T12:16:23.493411Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                   title                                        ingredients  \\\n0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n\n                                          directions  \\\n0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n1  [\"Place chipped beef on bottom of baking dish....   \n2  [\"In a slow cooker, combine all ingredients. C...   \n3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n4  [\"Combine first four ingredients and press in ...   \n\n                                                 NER  \\\n0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...   \n1  [\"beef\", \"chicken breasts\", \"cream of mushroom...   \n2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...   \n3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...   \n4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...   \n\n                                                text  \n0  Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...  \n1  Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...  \n2  Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...  \n3  Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...  \n4  Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>NER</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No-Bake Nut Cookies</td>\n      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n      <td>Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jewell Ball'S Chicken</td>\n      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n      <td>[\"Place chipped beef on bottom of baking dish....</td>\n      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n      <td>Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creamy Corn</td>\n      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n      <td>Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chicken Funny</td>\n      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n      <td>Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Reeses Cups(Candy)</td>\n      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n      <td>[\"Combine first four ingredients and press in ...</td>\n      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n      <td>Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"ids = []\na_masks = []\n\nmax_length = 256\n\nfor index, row in df.iterrows():\n    tokenized_text = tokenizer(\n                    row['text'],\n                    truncation=True,\n                    padding=\"max_length\",\n                    max_length=max_length,\n                    return_tensors=\"pt\"\n                    )\n\n    ids.append(tokenized_text['input_ids'])\n    a_masks.append(tokenized_text['attention_mask'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:16:23.494649Z","iopub.execute_input":"2025-05-05T12:16:23.494930Z","iopub.status.idle":"2025-05-05T12:17:41.498140Z","shell.execute_reply.started":"2025-05-05T12:16:23.494912Z","shell.execute_reply":"2025-05-05T12:17:41.497545Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"ids[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:41.499527Z","iopub.execute_input":"2025-05-05T12:17:41.499755Z","iopub.status.idle":"2025-05-05T12:17:41.504494Z","shell.execute_reply.started":"2025-05-05T12:17:41.499739Z","shell.execute_reply":"2025-05-05T12:17:41.503814Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 256])"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"a_masks[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:41.505115Z","iopub.execute_input":"2025-05-05T12:17:41.505288Z","iopub.status.idle":"2025-05-05T12:17:41.517319Z","shell.execute_reply.started":"2025-05-05T12:17:41.505274Z","shell.execute_reply":"2025-05-05T12:17:41.516620Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 256])"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import torch\n\ninput_id = torch.squeeze(ids[0], dim=0)\nprint(input_id.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:41.518110Z","iopub.execute_input":"2025-05-05T12:17:41.518367Z","iopub.status.idle":"2025-05-05T12:17:41.529321Z","shell.execute_reply.started":"2025-05-05T12:17:41.518346Z","shell.execute_reply":"2025-05-05T12:17:41.528679Z"}},"outputs":[{"name":"stdout","text":"torch.Size([256])\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"final_ids = []\nfinal_a_masks = []\n\nfor i in ids:\n    input_ids = torch.squeeze(i, dim=0)\n    final_ids.append(input_ids.tolist())\n\nfor i in a_masks:\n    a_mask = torch.squeeze(i, dim=0)\n    final_a_masks.append(a_mask.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:41.529963Z","iopub.execute_input":"2025-05-05T12:17:41.530156Z","iopub.status.idle":"2025-05-05T12:17:44.948488Z","shell.execute_reply.started":"2025-05-05T12:17:41.530143Z","shell.execute_reply":"2025-05-05T12:17:44.947917Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"df['input_ids'] = final_ids\ndf['attention_masks'] = final_a_masks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:44.949196Z","iopub.execute_input":"2025-05-05T12:17:44.949448Z","iopub.status.idle":"2025-05-05T12:17:44.974920Z","shell.execute_reply.started":"2025-05-05T12:17:44.949425Z","shell.execute_reply":"2025-05-05T12:17:44.974341Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:44.975741Z","iopub.execute_input":"2025-05-05T12:17:44.976000Z","iopub.status.idle":"2025-05-05T12:17:44.995928Z","shell.execute_reply.started":"2025-05-05T12:17:44.975977Z","shell.execute_reply":"2025-05-05T12:17:44.995393Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                   title                                        ingredients  \\\n0    No-Bake Nut Cookies  [\"1 c. firmly packed brown sugar\", \"1/2 c. eva...   \n1  Jewell Ball'S Chicken  [\"1 small jar chipped beef, cut up\", \"4 boned ...   \n2            Creamy Corn  [\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...   \n3          Chicken Funny  [\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...   \n4   Reeses Cups(Candy)    [\"1 c. peanut butter\", \"3/4 c. graham cracker ...   \n\n                                          directions  \\\n0  [\"In a heavy 2-quart saucepan, mix brown sugar...   \n1  [\"Place chipped beef on bottom of baking dish....   \n2  [\"In a slow cooker, combine all ingredients. C...   \n3  [\"Boil and debone chicken.\", \"Put bite size pi...   \n4  [\"Combine first four ingredients and press in ...   \n\n                                                 NER  \\\n0  [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...   \n1  [\"beef\", \"chicken breasts\", \"cream of mushroom...   \n2  [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...   \n3  [\"chicken\", \"chicken gravy\", \"cream of mushroo...   \n4  [\"peanut butter\", \"graham cracker crumbs\", \"bu...   \n\n                                                text  \\\n0  Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...   \n1  Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...   \n2  Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...   \n3  Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...   \n4  Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...   \n\n                                           input_ids  \\\n0  [37523, 11851, 25, 1400, 12, 33, 539, 11959, 4...   \n1  [37523, 11851, 25, 3370, 695, 6932, 6, 50, 164...   \n2  [37523, 11851, 25, 19979, 88, 11424, 198, 198,...   \n3  [37523, 11851, 25, 16405, 40473, 198, 198, 412...   \n4  [37523, 11851, 25, 797, 274, 274, 41611, 7, 34...   \n\n                                     attention_masks  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>NER</th>\n      <th>text</th>\n      <th>input_ids</th>\n      <th>attention_masks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No-Bake Nut Cookies</td>\n      <td>[\"1 c. firmly packed brown sugar\", \"1/2 c. eva...</td>\n      <td>[\"In a heavy 2-quart saucepan, mix brown sugar...</td>\n      <td>[\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...</td>\n      <td>Recipe Title: No-Bake Nut Cookies\\n\\nIngredien...</td>\n      <td>[37523, 11851, 25, 1400, 12, 33, 539, 11959, 4...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jewell Ball'S Chicken</td>\n      <td>[\"1 small jar chipped beef, cut up\", \"4 boned ...</td>\n      <td>[\"Place chipped beef on bottom of baking dish....</td>\n      <td>[\"beef\", \"chicken breasts\", \"cream of mushroom...</td>\n      <td>Recipe Title: Jewell Ball'S Chicken\\n\\nIngredi...</td>\n      <td>[37523, 11851, 25, 3370, 695, 6932, 6, 50, 164...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creamy Corn</td>\n      <td>[\"2 (16 oz.) pkg. frozen corn\", \"1 (8 oz.) pkg...</td>\n      <td>[\"In a slow cooker, combine all ingredients. C...</td>\n      <td>[\"frozen corn\", \"cream cheese\", \"butter\", \"gar...</td>\n      <td>Recipe Title: Creamy Corn\\n\\nIngredients:\\n[\"2...</td>\n      <td>[37523, 11851, 25, 19979, 88, 11424, 198, 198,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chicken Funny</td>\n      <td>[\"1 large whole chicken\", \"2 (10 1/2 oz.) cans...</td>\n      <td>[\"Boil and debone chicken.\", \"Put bite size pi...</td>\n      <td>[\"chicken\", \"chicken gravy\", \"cream of mushroo...</td>\n      <td>Recipe Title: Chicken Funny\\n\\nIngredients:\\n[...</td>\n      <td>[37523, 11851, 25, 16405, 40473, 198, 198, 412...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Reeses Cups(Candy)</td>\n      <td>[\"1 c. peanut butter\", \"3/4 c. graham cracker ...</td>\n      <td>[\"Combine first four ingredients and press in ...</td>\n      <td>[\"peanut butter\", \"graham cracker crumbs\", \"bu...</td>\n      <td>Recipe Title: Reeses Cups(Candy)  \\n\\nIngredie...</td>\n      <td>[37523, 11851, 25, 797, 274, 274, 41611, 7, 34...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"from datasets import Dataset\n\ndf = Dataset.from_pandas(df)\n\nprint(df)\nprint(type(df))  # Should output: <class 'datasets.arrow_dataset.Dataset'>","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:44.997630Z","iopub.execute_input":"2025-05-05T12:17:44.998282Z","iopub.status.idle":"2025-05-05T12:17:51.993568Z","shell.execute_reply.started":"2025-05-05T12:17:44.998245Z","shell.execute_reply":"2025-05-05T12:17:51.992840Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['title', 'ingredients', 'directions', 'NER', 'text', 'input_ids', 'attention_masks'],\n    num_rows: 100000\n})\n<class 'datasets.arrow_dataset.Dataset'>\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import peft\nfrom peft import LoraConfig, get_peft_model\n\nlora_config = LoraConfig(\n    r=2,\n    lora_alpha=8,\n    target_modules=[\"c_attn\"],\n    lora_dropout=0.05, \n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:51.994511Z","iopub.execute_input":"2025-05-05T12:17:51.994776Z","iopub.status.idle":"2025-05-05T12:17:51.998616Z","shell.execute_reply.started":"2025-05-05T12:17:51.994758Z","shell.execute_reply":"2025-05-05T12:17:51.998068Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"peft_model = get_peft_model(foundation_model, lora_config)\nprint(peft_model.print_trainable_parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:51.999426Z","iopub.execute_input":"2025-05-05T12:17:51.999725Z","iopub.status.idle":"2025-05-05T12:17:52.887603Z","shell.execute_reply.started":"2025-05-05T12:17:51.999701Z","shell.execute_reply":"2025-05-05T12:17:52.886980Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora.py:299: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 196,608 || all params: 355,019,776 || trainable%: 0.05537945018589612\nNone\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import transformers\nfrom transformers import TrainingArguments, Trainer\nimport os\n\noutput_directory = os.path.join(\"../cache/working\", \"peft_lab_outputs\")\ntraining_args = TrainingArguments(\n    report_to=\"none\",\n    output_dir=output_directory,\n    auto_find_batch_size=True,\n    learning_rate= 3e-2, # Higher learning rate than full fine-tuning.\n    num_train_epochs=1,\n    logging_steps=100,\n    #use_cpu=True\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=df,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T12:17:52.888281Z","iopub.execute_input":"2025-05-05T12:17:52.888491Z","iopub.status.idle":"2025-05-05T14:14:19.883239Z","shell.execute_reply.started":"2025-05-05T12:17:52.888475Z","shell.execute_reply":"2025-05-05T14:14:19.882607Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 1:56:22, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>3.305700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.176600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.316000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.203800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.068200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.302200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.221000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.088900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.282200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.684700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.727500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.641200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>3.701500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.665900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.717300</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>3.699100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>3.641300</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>3.687700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>3.653600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.665200</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>3.639000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>3.669000</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>3.671000</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>3.737200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.675600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>3.686600</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.708200</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>3.712600</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>3.733500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.712000</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>3.687500</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>3.706000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>3.722400</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>3.674100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.673200</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>3.774600</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>3.692300</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>3.687700</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>3.672400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.683300</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>3.635400</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>3.678000</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>3.669400</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>3.700400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.724300</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>3.694500</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>3.647000</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>3.644500</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>3.670800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.715100</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>3.636600</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>3.713600</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>3.728800</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>3.701200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>3.725500</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>3.718100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>3.726400</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>3.714500</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>3.653100</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>3.662100</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>3.683700</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>3.722500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6250, training_loss=3.6223760107421876, metrics={'train_runtime': 6983.7067, 'train_samples_per_second': 14.319, 'train_steps_per_second': 0.895, 'total_flos': 4.64652337152e+16, 'train_loss': 3.6223760107421876, 'epoch': 1.0})"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}